# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  file {
    path => "E:/Reveation/PharmUtilization.txt"
    start_position => beginning
    # to read from the beginning of file
    #sincedb_path => "/dev/null"
  }
}

filter {

    csv {

	#autodetect_column_names => true
	#autogenerate_column_names => true
	separator => "|"
   

columns =>
      [
	"PharmID","Vendor","claimDate","GroupNumber","GroupName","PaidClaims","RetailPrice",
	"MemberCost","TotalSavings","RXCount","Adjustments","StartDate","EndDate","PharmacyID",
	"PharmacyName","DrugName","UtilizationSummaryTypeId","ImportFile","CompareHash",
	"ETL_InsertDate","ETL_UpdateDate"
]
    }
 date {
      match => ["claimDate","YYYY-MM-DD HH:mm:ss"]
      target => "claimDate"
   }
   mutate {convert => ["PharmID", "integer"]}
   mutate {convert => ["GroupNumber", "integer"]}
   mutate {convert => ["PaidClaims", "integer"]}
   mutate {convert => ["RetailPrice", "float"]}
   mutate {convert => ["MemberCost", "float"]}
   mutate {convert => ["TotalSavings", "float"]}
   

}

output {
  elasticsearch {
    hosts => ["https://c4d446be8f634f87b3d22e2a29953a15.eastus2.azure.elastic-cloud.com:9243"]
    index => "pharmdemo1"
    user => "elastic"
    password => "uSNUSbN4gFcdnUxQhGTfZOqu"
  }
}
